{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
        "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
        "You should have received a copy of the GNU General Public License along with this program. If not, see <https://www.gnu.org/licenses/>."
      ],
      "metadata": {
        "id": "oKsma5bnaWAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kZYDaHHt-fxS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t-Wwfe1ZAj4L"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Sets up vocabulary for the representation of MIDI files using Oore et al, 2018 vocabulary\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/vocabulary.py with modifications\n",
        "Velocity events were removed\n",
        "Start and end tokens were removed\n",
        "LTH variable renamed to max_time_shift for easier understandability\n",
        "DIV variable renamed to time_shift for easier understandability\n",
        "\"\"\"\n",
        "note_on_events = 128\n",
        "note_off_events = note_on_events\n",
        "note_events = note_on_events + note_off_events\n",
        "time_shift = 8\n",
        "max_time_shift = 1000\n",
        "time_shift_events = max_time_shift // time_shift\n",
        "total_midi_events = note_on_events + note_off_events + time_shift_events\n",
        "\n",
        "# create vocabulary\n",
        "note_on_vocab = [f\"note_on_{i}\" for i in range(note_on_events)]\n",
        "note_off_vocab = [f\"note_off_{i}\" for i in range(note_off_events)]\n",
        "time_shift_vocab = [f\"time_shift_{i}\" for i in range(time_shift_events)]\n",
        "vocab = [\"<pad>\"] + note_on_vocab + note_off_vocab + time_shift_vocab\n",
        "vocab_size = len(vocab)\n",
        "pad_token = vocab.index(\"<pad>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hst1IDD_AlYR"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Converts a list of events to a list of indices\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/vocabulary.py\n",
        "\"\"\"\n",
        "def events_to_indices(event_list, _vocab=None):\n",
        "    if _vocab is None:\n",
        "        _vocab = vocab\n",
        "    index_list = []\n",
        "    for event in event_list:\n",
        "        index_list.append(_vocab.index(event))\n",
        "    return index_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K2fMz4FzBpVJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Converts a list of indices to a list of events\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/vocabulary.py\n",
        "\"\"\"\n",
        "def indices_to_events(index_list, _vocab=None):\n",
        "    if _vocab is None:\n",
        "        _vocab = vocab\n",
        "    event_list = []\n",
        "    for idx in index_list:\n",
        "        event_list.append(_vocab[idx])\n",
        "    return event_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZUS45Hb2CNPw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Customing rounding function that rounds 0.5 to the greater integer\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/vocabulary.py\n",
        "\"\"\"\n",
        "def round_(a):\n",
        "    b = a // 1\n",
        "    decimal_digits = a % 1\n",
        "    adder = 1 if decimal_digits >= 0.5 else 0\n",
        "    return int(b + adder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l9daWV_hCBX2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Handles the creation of time shift events from Oore et al, 2018 vocabulary\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/vocabulary.py\n",
        "LTH variable renamed to max_time_shift for easier understandability\n",
        "DIV variable renamed to time_shift for easier understandability\n",
        "\"\"\"\n",
        "def time_cutter(time, max_time_shift=max_time_shift, time_shift=time_shift):\n",
        "    time_shifts = []\n",
        "\n",
        "    # assume time = k * lth, k >= 0; add k max_time_shifts (lth // div) to time_shifts\n",
        "    for i in range(time // max_time_shift):\n",
        "        time_shifts.append(round_(max_time_shift / time_shift))   # custom round for consistent rounding of 0.5\n",
        "    leftover_time_shift = round_((time % max_time_shift) / time_shift)\n",
        "    time_shifts.append(leftover_time_shift) if leftover_time_shift > 0 else None\n",
        "\n",
        "    return time_shifts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mjsw5w4OBuE-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Adds time shift events to index list and event list using delta time value calulated in the midi parser function\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/vocabulary.py\n",
        "\"\"\"\n",
        "def time_to_events(delta_time, event_list=None, index_list=None, _vocab=None):\n",
        "    if _vocab is None:\n",
        "        _vocab = vocab\n",
        "    time = time_cutter(delta_time)\n",
        "    for i in time:\n",
        "        # repeatedly create and append time events to the input lists\n",
        "        idx = note_on_events + note_off_events + i\n",
        "        if event_list is not None:\n",
        "            event_list.append(_vocab[idx])\n",
        "        if index_list is not None:\n",
        "            index_list.append(idx)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DCAn4XQe_eLR"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Samples sequences to a specified length\n",
        "\"\"\"\n",
        "def sample_data(seqs, length):\n",
        "  data = []\n",
        "  for seq in seqs:\n",
        "    data.append(seq[:length])\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qbhr4eEEARY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c2eaa9-a270-43cf-b51b-9e632ef0e9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Connect to Google Drive for importing and exporting files\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uHlBLdpUKhWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3578c174-593c-42ab-e900-50fc0ba9e621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Allow for connection to GPU\n",
        "\"\"\"\n",
        "from torch import cuda, device as d\n",
        "if cuda.is_available():\n",
        "    dev = \"cuda\"\n",
        "else:\n",
        "    dev = \"cpu\"\n",
        "device = d(dev)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YzM9b4KmJ28E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac8c10f-98d2-4df9-e02c-d0439301e3bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mido\n",
            "  Downloading mido-1.3.0-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.10/dist-packages (from mido) (23.1)\n",
            "Installing collected packages: mido\n",
            "Successfully installed mido-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mido\n",
        "import mido\n",
        "from torch import LongTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pygfVsauJoTD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Translates midi files into Oore et. al, 2018 vocabulary\n",
        "Returns both a LongTensor of indices and a list of events as strings\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/tokenizer.py with modifications\n",
        "Handling of pedal events removed\n",
        "Code to set tempo of midi tracks to 500000 microseconds per beat (120 bpm) added\n",
        "Code to handle velocity events removed\n",
        "delta_time is scaled up by a factor of 5\n",
        "\"\"\"\n",
        "def midi_parser(fname=None, mid=None):\n",
        "    if not ((fname is None) ^ (mid is None)):\n",
        "        raise ValueError(\"Input one of fname or mid, not both or neither\")\n",
        "\n",
        "    tempo_in_microseconds_per_beat = 500000\n",
        "\n",
        "    if fname is not None:\n",
        "        mid = mido.MidiFile(fname)\n",
        "\n",
        "    # Find original tempo\n",
        "    original_tempo = None\n",
        "    for track in mid.tracks:\n",
        "        for msg in track:\n",
        "            if msg.is_meta and msg.type == 'set_tempo':\n",
        "                original_tempo = msg.tempo\n",
        "                break\n",
        "        if original_tempo is not None:\n",
        "            break\n",
        "\n",
        "    # Change tempo to desired value\n",
        "    for track in mid.tracks:\n",
        "        for msg in track:\n",
        "            if msg.is_meta and msg.type == 'set_tempo':\n",
        "                msg.tempo = tempo_in_microseconds_per_beat\n",
        "\n",
        "    # things needed for conversion\n",
        "    delta_time = 0          # time between important midi messages\n",
        "    event_list = []         # list of events in vocab\n",
        "    index_list = []         # list of indices in vocabdelta_time = 0\n",
        "\n",
        "    # translate midi file to event list\n",
        "    for track in mid.tracks:\n",
        "        for msg in track:\n",
        "\n",
        "            # increase delta_time by msg time for all messages and scale by 5\n",
        "            delta_time += msg.time * 5\n",
        "\n",
        "            if msg.is_meta:\n",
        "                continue\n",
        "\n",
        "            t = msg.type\n",
        "\n",
        "            if t == \"note_on\":\n",
        "                idx = msg.note + 1\n",
        "            elif t == \"note_off\":\n",
        "                idx = note_on_events + msg.note + 1\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            time_to_events(delta_time, event_list=event_list, index_list=index_list)\n",
        "            delta_time = 0\n",
        "\n",
        "            event_list.append(vocab[idx])\n",
        "            index_list.append(idx)\n",
        "\n",
        "    return LongTensor(index_list), event_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nDPu4VpPAW_I"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Specify the directory containing the MIDI files\n",
        "\"\"\"\n",
        "midi_directory = \"/content/drive/MyDrive/dissertationMidis\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAxQo9oXzyjs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fyTDhqMzIWKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22cc2a7-7ced-4b0e-bc5e-363b0b721c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index List:\n",
            "tensor([ 72,  68,  65,  53, 381, 311, 200, 196, 193, 181,  75,  67,  70,  63,\n",
            "         51, 376, 195, 198, 191, 179,  68,  65,  61,  49, 346, 196, 193, 189,\n",
            "        177,  67,  63,  51, 346, 203, 195, 191, 179,  72,  68,  65,  53, 381,\n",
            "        311, 200, 196, 193, 181,  75,  67,  70,  63,  51, 376, 195, 198, 191,\n",
            "        179,  68,  65,  61,  49, 346, 196, 193, 189, 177,  67,  63,  51, 346,\n",
            "        203, 195, 191, 179,  72,  68,  65,  53, 381, 311, 200, 196, 193, 181,\n",
            "         75,  67,  70,  63,  51, 376, 195, 198, 191, 179,  68,  65,  61,  49,\n",
            "        346, 196, 193, 189, 177,  67,  63,  51, 346, 203, 195, 191, 179,  72,\n",
            "         68,  65,  53, 381, 311, 200, 196, 193, 181,  75,  67,  70,  63,  51,\n",
            "        376, 195, 198, 191, 179,  68,  65,  61,  49, 346, 196, 193, 189, 177,\n",
            "         67,  63,  51, 346, 203, 195, 191, 179,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
            "Event List:\n",
            "['note_on_71', 'note_on_67', 'note_on_64', 'note_on_52', 'time_shift_124', 'time_shift_54', 'note_off_71', 'note_off_67', 'note_off_64', 'note_off_52', 'note_on_74', 'note_on_66', 'note_on_69', 'note_on_62', 'note_on_50', 'time_shift_119', 'note_off_66', 'note_off_69', 'note_off_62', 'note_off_50', 'note_on_67', 'note_on_64', 'note_on_60', 'note_on_48', 'time_shift_89', 'note_off_67', 'note_off_64', 'note_off_60', 'note_off_48', 'note_on_66', 'note_on_62', 'note_on_50', 'time_shift_89', 'note_off_74', 'note_off_66', 'note_off_62', 'note_off_50', 'note_on_71', 'note_on_67', 'note_on_64', 'note_on_52', 'time_shift_124', 'time_shift_54', 'note_off_71', 'note_off_67', 'note_off_64', 'note_off_52', 'note_on_74', 'note_on_66', 'note_on_69', 'note_on_62', 'note_on_50', 'time_shift_119', 'note_off_66', 'note_off_69', 'note_off_62', 'note_off_50', 'note_on_67', 'note_on_64', 'note_on_60', 'note_on_48', 'time_shift_89', 'note_off_67', 'note_off_64', 'note_off_60', 'note_off_48', 'note_on_66', 'note_on_62', 'note_on_50', 'time_shift_89', 'note_off_74', 'note_off_66', 'note_off_62', 'note_off_50', 'note_on_71', 'note_on_67', 'note_on_64', 'note_on_52', 'time_shift_124', 'time_shift_54', 'note_off_71', 'note_off_67', 'note_off_64', 'note_off_52', 'note_on_74', 'note_on_66', 'note_on_69', 'note_on_62', 'note_on_50', 'time_shift_119', 'note_off_66', 'note_off_69', 'note_off_62', 'note_off_50', 'note_on_67', 'note_on_64', 'note_on_60', 'note_on_48', 'time_shift_89', 'note_off_67', 'note_off_64', 'note_off_60', 'note_off_48', 'note_on_66', 'note_on_62', 'note_on_50', 'time_shift_89', 'note_off_74', 'note_off_66', 'note_off_62', 'note_off_50', 'note_on_71', 'note_on_67', 'note_on_64', 'note_on_52', 'time_shift_124', 'time_shift_54', 'note_off_71', 'note_off_67', 'note_off_64', 'note_off_52', 'note_on_74', 'note_on_66', 'note_on_69', 'note_on_62', 'note_on_50', 'time_shift_119', 'note_off_66', 'note_off_69', 'note_off_62', 'note_off_50', 'note_on_67', 'note_on_64', 'note_on_60', 'note_on_48', 'time_shift_89', 'note_off_67', 'note_off_64', 'note_off_60', 'note_off_48', 'note_on_66', 'note_on_62', 'note_on_50', 'time_shift_89', 'note_off_74', 'note_off_66', 'note_off_62', 'note_off_50', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Iterate through MIDI files, extract data, represent data as Oore et. al, 2018 vocabulary, convert to a tensor, then add to list (only indices are added not events)\n",
        "Tensors are then shortened to a length of 220 if longer or padded to a length of 220 if shorter\n",
        "The list of tensors is then shuffled\n",
        "\n",
        "Based off of code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/preprocessing.py (Lines 224 - 251)\n",
        "\"\"\"\n",
        "training_seqs = []\n",
        "\n",
        "for filename in os.listdir(midi_directory):\n",
        "    if filename.endswith(\".mid\"):\n",
        "        file_path = os.path.join(midi_directory, filename)\n",
        "        try:\n",
        "            index_tensor = midi_parser(file_path)[0]\n",
        "            training_seqs.append(index_tensor)\n",
        "        except OSError:\n",
        "            pass\n",
        "\n",
        "training_seqs = sample_data(training_seqs, length=220)\n",
        "training_seqs = torch.nn.utils.rnn.pad_sequence(training_seqs, padding_value=pad_token).transpose(-1, -2)\n",
        "training_seqs = training_seqs[torch.randperm(training_seqs.shape[0])]\n",
        "\n",
        "print(\"Index List:\")\n",
        "print(training_seqs[0])\n",
        "\n",
        "event_list = indices_to_events(training_seqs[0].tolist())\n",
        "print(\"Event List:\")\n",
        "print(event_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Fsou0jPq_qP4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Translates either a sequence events or indices in the Oore et. al, 2018 vocabulary into a MIDI file\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/tokenizer.py with modifications\n",
        "DIV variable renamed to time_shift for easier understandability\n",
        "Handling of velocity events removed\n",
        "Tempo changed to 500000\n",
        "\"\"\"\n",
        "def list_parser(index_list=None, event_list=None, fname=\"bloop\", tempo=500000):\n",
        "    # take only one of event_list or index_list to translate\n",
        "    if not ((index_list is None) ^ (event_list is None)):\n",
        "        raise ValueError(\"Input one of index_list or event_list, not both or neither\")\n",
        "\n",
        "    # check index_list is ints, assuming 1d list\n",
        "    if index_list is not None:\n",
        "        try:\n",
        "            # assume torch tensor\n",
        "            if not all([isinstance(i.item(), int) for i in index_list]):\n",
        "                raise ValueError(\"All indices in index_list must be int type\")\n",
        "        except AttributeError:\n",
        "            # otherwise assume normal ,jst\n",
        "            if not all([isinstance(i, int) for i in index_list]):\n",
        "                raise ValueError(\"All indices in index_list must be int type\")\n",
        "\n",
        "    # check event_list is str, assuming 1d list and convert to index_list\n",
        "    if event_list is not None:\n",
        "        if not all(isinstance(i, str) for i in event_list):\n",
        "            raise ValueError(\"All events in event_list must be str type\")\n",
        "        index_list = events_to_indices(event_list)\n",
        "\n",
        "    # set up midi file\n",
        "    mid = mido.MidiFile()\n",
        "    meta_track = mido.MidiTrack()\n",
        "    track = mido.MidiTrack()\n",
        "\n",
        "    # meta messages; meta time is 0 everywhere to prevent delay in playing notes\n",
        "    meta_track.append(mido.MetaMessage(\"track_name\").copy(name=fname, time=0))\n",
        "    meta_track.append(mido.MetaMessage(\"smpte_offset\"))\n",
        "    # assume time_signature is 4/4\n",
        "    time_sig = mido.MetaMessage(\"time_signature\")\n",
        "    time_sig = time_sig.copy(numerator=4, denominator=4, time=0)\n",
        "    meta_track.append(time_sig)\n",
        "    # assume key_signature is C\n",
        "    key_sig = mido.MetaMessage(\"key_signature\", time=0)\n",
        "    meta_track.append(key_sig)\n",
        "    # assume tempo is constant at input tempo\n",
        "    set_tempo = mido.MetaMessage(\"set_tempo\")\n",
        "    set_tempo = set_tempo.copy(tempo=tempo, time=0)\n",
        "    meta_track.append(set_tempo)\n",
        "    # end of meta track\n",
        "    end = mido.MetaMessage(\"end_of_track\").copy(time=0)\n",
        "    meta_track.append(end)\n",
        "\n",
        "    # set up the piano; default channel is 0 everywhere; program=0 -> piano\n",
        "    program = mido.Message(\"program_change\", channel=0, program=0, time=0)\n",
        "    track.append(program)\n",
        "    # dummy pedal off message; control should be < 64\n",
        "    cc = mido.Message(\"control_change\", time=0)\n",
        "    track.append(cc)\n",
        "\n",
        "    # things needed for conversion\n",
        "    delta_time = 0\n",
        "\n",
        "    # reconstruct the performance\n",
        "    for idx in index_list:\n",
        "        # if torch tensor, get item\n",
        "        try:\n",
        "            idx = idx.item()\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        # if pad token, continue\n",
        "        if idx <= 0:\n",
        "            continue\n",
        "        # adjust idx to ignore pad token\n",
        "        idx = idx - 1\n",
        "\n",
        "        # note messages\n",
        "        if 0 <= idx < note_on_events + note_off_events:\n",
        "            # note on event\n",
        "            if 0 <= idx < note_on_events:\n",
        "                note = idx\n",
        "                t = \"note_on\"\n",
        "            # note off event\n",
        "            else:\n",
        "                note = idx - note_on_events\n",
        "                t = \"note_off\"\n",
        "\n",
        "            # create note message and append to track\n",
        "            msg = mido.Message(t)\n",
        "            msg = msg.copy(note=note, time=delta_time)\n",
        "            track.append(msg)\n",
        "\n",
        "            # reinitialize delta_time and velocity to handle subsequent notes\n",
        "            delta_time = 0\n",
        "\n",
        "        # time shift event\n",
        "        elif note_on_events + note_off_events <= idx < note_on_events + note_off_events + time_shift_events:\n",
        "            # find cut time in range (1, time_shift_events)\n",
        "            cut_time = idx - (note_on_events + note_off_events - 1)\n",
        "            # scale cut_time by time_shift (from vocabulary) to find time in ms; add to delta_time\n",
        "            delta_time += cut_time * time_shift\n",
        "\n",
        "    # end the track\n",
        "    end = mido.MetaMessage(\"end_of_track\").copy(time=0)\n",
        "    track.append(end)\n",
        "\n",
        "    # append finalized track and return midi file\n",
        "    mid.tracks.append(meta_track)\n",
        "    mid.tracks.append(track)\n",
        "    return mid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uN1XUhKOCsz7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Converts a list of indeces to a midi file (using list_parser) and saves the file\n",
        "\n",
        "Code from Gomatam's repository https://github.com/spectraldoy/music-transformer/blob/main/generate.py with a minor modification\n",
        "tempo chnaged to 500000\n",
        "verbose parameter removed\n",
        "commented code for saving other file formats removed\n",
        "\"\"\"\n",
        "def audiate(token_ids, save_path=\"/content/drive/MyDrive/genMidis\", tempo=500000):\n",
        "    # set file to a midi file\n",
        "    if save_path.endswith(\".midi\"):\n",
        "        save_path = save_path[:-1]\n",
        "    elif save_path.endswith(\".mid\"):\n",
        "        pass\n",
        "    else:\n",
        "        save_path += \".mid\"\n",
        "\n",
        "    # create and save the midi file\n",
        "    mid = list_parser(index_list=token_ids, fname=save_path[:-4], tempo=tempo)\n",
        "    mid.save(save_path)\n",
        "\n",
        "    print(\"Done\")\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "It6VP-hRYG06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308fd57d-8321-483f-e20c-0c97c7df0195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data Shape: torch.Size([1219, 219])\n",
            "Target Data Shape: torch.Size([1219, 219])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Creates input and target sequences as a list of tensors, then converts each list to a single tensor\n",
        "\"\"\"\n",
        "input_sequences = []\n",
        "target_sequences = []\n",
        "\n",
        "# Iterate through the parsed MIDI data to create input and target sequences\n",
        "for seq in training_seqs:\n",
        "\n",
        "    input_seq = seq[:-1]\n",
        "    target_seq = seq[1:]\n",
        "\n",
        "    input_sequences.append(input_seq)\n",
        "    target_sequences.append(target_seq)\n",
        "\n",
        "input_data = torch.stack(input_sequences)\n",
        "target_data = torch.stack(target_sequences)\n",
        "\n",
        "print(\"Input Data Shape:\", input_data.shape)\n",
        "print(\"Target Data Shape:\", target_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kX_JZwcGuUFs"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "r0U1SRA7JIg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b8d575-3226-4a6b-ac63-e9fea2caeaa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNModel(\n",
            "  (lstm_layers): LSTM(382, 430, num_layers=3, batch_first=True)\n",
            "  (fc): Linear(in_features=430, out_features=382, bias=True)\n",
            ")\n",
            "Epoch 1, Average Loss: 4.9564\n",
            "Epoch 2, Average Loss: 3.7445\n",
            "Epoch 3, Average Loss: 3.8761\n",
            "Epoch 4, Average Loss: 3.9072\n",
            "Epoch 5, Average Loss: 2.5802\n",
            "Epoch 6, Average Loss: 3.2834\n",
            "Epoch 7, Average Loss: 3.3762\n",
            "Epoch 8, Average Loss: 4.4002\n",
            "Epoch 9, Average Loss: 2.9282\n",
            "Epoch 10, Average Loss: 3.8030\n",
            "Epoch 11, Average Loss: 3.0699\n",
            "Epoch 12, Average Loss: 2.0415\n",
            "Epoch 13, Average Loss: 2.9115\n",
            "Epoch 14, Average Loss: 3.2534\n",
            "Epoch 15, Average Loss: 2.3916\n",
            "Epoch 16, Average Loss: 1.9978\n",
            "Epoch 17, Average Loss: 3.3815\n",
            "Epoch 18, Average Loss: 3.0800\n",
            "Epoch 19, Average Loss: 2.0553\n",
            "Epoch 20, Average Loss: 3.2181\n",
            "Epoch 21, Average Loss: 1.8199\n",
            "Epoch 22, Average Loss: 2.1590\n",
            "Epoch 23, Average Loss: 1.5977\n",
            "Epoch 24, Average Loss: 2.9344\n",
            "Epoch 25, Average Loss: 1.5438\n",
            "Epoch 26, Average Loss: 2.3152\n",
            "Epoch 27, Average Loss: 1.4491\n",
            "Epoch 28, Average Loss: 2.0866\n",
            "Epoch 29, Average Loss: 2.8725\n",
            "Epoch 30, Average Loss: 1.8079\n",
            "Epoch 31, Average Loss: 2.0234\n",
            "Epoch 32, Average Loss: 1.7343\n",
            "Epoch 33, Average Loss: 2.0357\n",
            "Epoch 34, Average Loss: 1.8299\n",
            "Epoch 35, Average Loss: 1.3524\n",
            "Epoch 36, Average Loss: 1.2486\n",
            "Epoch 37, Average Loss: 1.3225\n",
            "Epoch 38, Average Loss: 2.1105\n",
            "Epoch 39, Average Loss: 1.8395\n",
            "Epoch 40, Average Loss: 1.8215\n",
            "Epoch 41, Average Loss: 1.3760\n",
            "Epoch 42, Average Loss: 1.9567\n",
            "Epoch 43, Average Loss: 1.4577\n",
            "Epoch 44, Average Loss: 1.0864\n",
            "Epoch 45, Average Loss: 1.1856\n",
            "Epoch 46, Average Loss: 1.7439\n",
            "Epoch 47, Average Loss: 1.2406\n",
            "Epoch 48, Average Loss: 1.1539\n",
            "Epoch 49, Average Loss: 1.0911\n",
            "Epoch 50, Average Loss: 1.4447\n",
            "Epoch 51, Average Loss: 1.3420\n",
            "Epoch 52, Average Loss: 1.3974\n",
            "Epoch 53, Average Loss: 0.8809\n",
            "Epoch 54, Average Loss: 1.2851\n",
            "Epoch 55, Average Loss: 0.6064\n",
            "Epoch 56, Average Loss: 1.4658\n",
            "Epoch 57, Average Loss: 1.2692\n",
            "Epoch 58, Average Loss: 1.3898\n",
            "Epoch 59, Average Loss: 0.7923\n",
            "Epoch 60, Average Loss: 0.9665\n",
            "Epoch 61, Average Loss: 0.8324\n",
            "Epoch 62, Average Loss: 0.8841\n",
            "Epoch 63, Average Loss: 0.6507\n",
            "Epoch 64, Average Loss: 0.6450\n",
            "Epoch 65, Average Loss: 0.4909\n",
            "Epoch 66, Average Loss: 1.1674\n",
            "Epoch 67, Average Loss: 0.6481\n",
            "Epoch 68, Average Loss: 0.3091\n",
            "Epoch 69, Average Loss: 0.6124\n",
            "Epoch 70, Average Loss: 0.3708\n",
            "Epoch 71, Average Loss: 0.6026\n",
            "Epoch 72, Average Loss: 0.4307\n",
            "Epoch 73, Average Loss: 0.4505\n",
            "Epoch 74, Average Loss: 0.8099\n",
            "Epoch 75, Average Loss: 0.3078\n",
            "Epoch 76, Average Loss: 0.4851\n",
            "Epoch 77, Average Loss: 0.2014\n",
            "Epoch 78, Average Loss: 0.3868\n",
            "Epoch 79, Average Loss: 0.5366\n",
            "Epoch 80, Average Loss: 0.2749\n",
            "Epoch 81, Average Loss: 0.4049\n",
            "Epoch 82, Average Loss: 0.3704\n",
            "Epoch 83, Average Loss: 0.1452\n",
            "Epoch 84, Average Loss: 0.2396\n",
            "Epoch 85, Average Loss: 0.2249\n",
            "Epoch 86, Average Loss: 0.1520\n",
            "Epoch 87, Average Loss: 0.1647\n",
            "Epoch 88, Average Loss: 0.1681\n",
            "Epoch 89, Average Loss: 0.1937\n",
            "Epoch 90, Average Loss: 0.1057\n",
            "Epoch 91, Average Loss: 0.1304\n",
            "Epoch 92, Average Loss: 0.3141\n",
            "Epoch 93, Average Loss: 0.1483\n",
            "Epoch 94, Average Loss: 0.1489\n",
            "Epoch 95, Average Loss: 0.1598\n",
            "Epoch 96, Average Loss: 0.1859\n",
            "Epoch 97, Average Loss: 0.1668\n",
            "Epoch 98, Average Loss: 0.0966\n",
            "Epoch 99, Average Loss: 0.1014\n",
            "Epoch 100, Average Loss: 0.0687\n",
            "Epoch 101, Average Loss: 0.0807\n",
            "Epoch 102, Average Loss: 0.1289\n",
            "Epoch 103, Average Loss: 0.1048\n",
            "Epoch 104, Average Loss: 0.0893\n",
            "Epoch 105, Average Loss: 0.0611\n",
            "Epoch 106, Average Loss: 0.0759\n",
            "Epoch 107, Average Loss: 0.0907\n",
            "Epoch 108, Average Loss: 0.0810\n",
            "Epoch 109, Average Loss: 0.1460\n",
            "Epoch 110, Average Loss: 0.0718\n",
            "Epoch 111, Average Loss: 0.0821\n",
            "Epoch 112, Average Loss: 0.0830\n",
            "Epoch 113, Average Loss: 0.0854\n",
            "Epoch 114, Average Loss: 0.0844\n",
            "Epoch 115, Average Loss: 0.1095\n",
            "Epoch 116, Average Loss: 0.1341\n",
            "Epoch 117, Average Loss: 0.1447\n",
            "Epoch 118, Average Loss: 0.1951\n",
            "Epoch 119, Average Loss: 0.2156\n",
            "Epoch 120, Average Loss: 0.1380\n",
            "Epoch 121, Average Loss: 0.1132\n",
            "Epoch 122, Average Loss: 0.0939\n",
            "Epoch 123, Average Loss: 0.0918\n",
            "Epoch 124, Average Loss: 0.0769\n",
            "Epoch 125, Average Loss: 0.0559\n",
            "Epoch 126, Average Loss: 0.0547\n",
            "Epoch 127, Average Loss: 0.0506\n",
            "Epoch 128, Average Loss: 0.0545\n",
            "Epoch 129, Average Loss: 0.0389\n",
            "Epoch 130, Average Loss: 0.0383\n",
            "Epoch 131, Average Loss: 0.0429\n",
            "Epoch 132, Average Loss: 0.0416\n",
            "Epoch 133, Average Loss: 0.0519\n",
            "Epoch 134, Average Loss: 0.0363\n",
            "Epoch 135, Average Loss: 0.0535\n",
            "Epoch 136, Average Loss: 0.0595\n",
            "Epoch 137, Average Loss: 0.0420\n",
            "Epoch 138, Average Loss: 0.0439\n",
            "Epoch 139, Average Loss: 0.0400\n",
            "Epoch 140, Average Loss: 0.0411\n",
            "Epoch 141, Average Loss: 0.0380\n",
            "Epoch 142, Average Loss: 0.0386\n",
            "Epoch 143, Average Loss: 0.0339\n",
            "Epoch 144, Average Loss: 0.0342\n",
            "Epoch 145, Average Loss: 0.0396\n",
            "Epoch 146, Average Loss: 0.0294\n",
            "Epoch 147, Average Loss: 0.0332\n",
            "Epoch 148, Average Loss: 0.0371\n",
            "Epoch 149, Average Loss: 0.0347\n",
            "Epoch 150, Average Loss: 0.0420\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "\"\"\"\n",
        "class RNNModel(nn.Module):\n",
        "    #Create structure of the model\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm_layers = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    #Initiate a forward pass\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        lstm_out, _ = self.lstm_layers(x, (h0.detach(), c0.detach()))\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n",
        "\n",
        "# Define the dimensions\n",
        "input_size = vocab_size\n",
        "hidden_size = 430\n",
        "output_size = vocab_size\n",
        "num_layers = 3\n",
        "learning_rate = 0.001\n",
        "\n",
        "#Move inputs and targets to gpu\n",
        "input_data = input_data.to(device)\n",
        "target_data = target_data.to(device)\n",
        "\n",
        "#Create dataset from inputs and targets then convert to dataloader for batch training and shuffling of batches\n",
        "dataset = torch.utils.data.TensorDataset(input_data, target_data)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "#Instantiate model\n",
        "model = RNNModel(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "print(model)\n",
        "\n",
        "#Specify loss and optimizers functions\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#Specify number of epochs for training\n",
        "EPOCHS = 150\n",
        "\n",
        "#Iterate through epochs\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    #Iterate through batches\n",
        "    for i, (inputs, targets) in enumerate(dataloader):\n",
        "        #Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # One-hot encode the inputs from the dataloader\n",
        "        inputs_one_hot = F.one_hot(inputs, num_classes=vocab_size).float()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs_one_hot)\n",
        "\n",
        "        #Loss calculation\n",
        "        loss = criterion(outputs.contiguous().view(-1, output_size), targets.contiguous().view(-1))\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    #Compute average loss over each epoch and print\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}, Average Loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nml79nnCkHB5"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Save trained model as a .pt file in Google Drive\n",
        "\"\"\"\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            },\"/content/drive/My Drive/genModels/model41.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load saved model from google drive, then generate the specified number of files of a specified length\n",
        "\"\"\"\n",
        "#Load saved model\n",
        "checkpoint = torch.load(\"/content/drive/My Drive/genModels/model41.pt\")\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "#Switch to eval mode for generation\n",
        "model.eval()\n",
        "\n",
        "#Specify length of each file and number of files\n",
        "num_files = 5\n",
        "sequence_length = 220\n",
        "\n",
        "#Initialize set for generated seeds\n",
        "generated_seeds = set()\n",
        "\n",
        "# Loop to generate multiple MIDI files\n",
        "for i in range(num_files):\n",
        "    while True:\n",
        "        #Generate random seed between 37 and 100\n",
        "        seed = torch.randint(37, 100, (1, 1)).to(device)\n",
        "\n",
        "        #Make sure seed has not already been generated\n",
        "        if seed.item() not in generated_seeds:\n",
        "            break\n",
        "\n",
        "    #Add to set to check for uniqueness of following generations\n",
        "    generated_seeds.add(seed.item())\n",
        "\n",
        "    #Add generated seed to list\n",
        "    generated_idx = [seed.item()]\n",
        "\n",
        "    #Loop for specified sequence length\n",
        "    for _ in range(sequence_length - 1):\n",
        "\n",
        "        #One hot encode index list\n",
        "        input_tensor = F.one_hot(torch.tensor(generated_idx).to(device), num_classes=382).float().unsqueeze(0)\n",
        "\n",
        "        # Make a prediction using the model without calculating gradients\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "\n",
        "        # Get the token ID with the highest score as the next token ID\n",
        "        next_event_idx = torch.argmax(output[0, -1, :], dim=0).item()\n",
        "        generated_idx.append(next_event_idx)\n",
        "\n",
        "    print(generated_idx)\n",
        "    generated_event = indices_to_events(generated_idx)\n",
        "    print(generated_event)\n",
        "\n",
        "    #Convert to MIDI and save\n",
        "    audiate(torch.tensor(generated_idx), save_path=f\"/content/drive/MyDrive/genMidis/generated_{i}.mid\")\n",
        "\n",
        "print(\"MIDI files generated and saved!\")\n"
      ],
      "metadata": {
        "id": "ysMx4iPl83s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56427f6-8e6f-4ac2-bbf9-58735744a811"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[97, 104, 108, 72, 91, 94, 89, 286, 200, 217, 70, 89, 286, 198, 217, 68, 316, 89, 286, 217, 89, 286, 196, 217, 63, 286, 191, 77, 286, 225, 232, 236, 219, 222, 205, 75, 108, 97, 104, 87, 91, 82, 286, 215, 87, 286, 215, 316, 84, 286, 212, 84, 286, 212, 316, 203, 236, 225, 232, 219, 210, 94, 91, 103, 99, 106, 72, 89, 286, 200, 217, 70, 89, 286, 198, 217, 68, 316, 89, 286, 217, 89, 286, 196, 217, 63, 286, 191, 77, 286, 222, 219, 231, 227, 234, 205, 99, 103, 106, 91, 82, 75, 87, 286, 215, 87, 286, 215, 316, 84, 286, 212, 84, 286, 212, 316, 231, 234, 219, 210, 203, 259, 227, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "['note_on_96', 'note_on_103', 'note_on_107', 'note_on_71', 'note_on_90', 'note_on_93', 'note_on_88', 'time_shift_29', 'note_off_71', 'note_off_88', 'note_on_69', 'note_on_88', 'time_shift_29', 'note_off_69', 'note_off_88', 'note_on_67', 'time_shift_59', 'note_on_88', 'time_shift_29', 'note_off_88', 'note_on_88', 'time_shift_29', 'note_off_67', 'note_off_88', 'note_on_62', 'time_shift_29', 'note_off_62', 'note_on_76', 'time_shift_29', 'note_off_96', 'note_off_103', 'note_off_107', 'note_off_90', 'note_off_93', 'note_off_76', 'note_on_74', 'note_on_107', 'note_on_96', 'note_on_103', 'note_on_86', 'note_on_90', 'note_on_81', 'time_shift_29', 'note_off_86', 'note_on_86', 'time_shift_29', 'note_off_86', 'time_shift_59', 'note_on_83', 'time_shift_29', 'note_off_83', 'note_on_83', 'time_shift_29', 'note_off_83', 'time_shift_59', 'note_off_74', 'note_off_107', 'note_off_96', 'note_off_103', 'note_off_90', 'note_off_81', 'note_on_93', 'note_on_90', 'note_on_102', 'note_on_98', 'note_on_105', 'note_on_71', 'note_on_88', 'time_shift_29', 'note_off_71', 'note_off_88', 'note_on_69', 'note_on_88', 'time_shift_29', 'note_off_69', 'note_off_88', 'note_on_67', 'time_shift_59', 'note_on_88', 'time_shift_29', 'note_off_88', 'note_on_88', 'time_shift_29', 'note_off_67', 'note_off_88', 'note_on_62', 'time_shift_29', 'note_off_62', 'note_on_76', 'time_shift_29', 'note_off_93', 'note_off_90', 'note_off_102', 'note_off_98', 'note_off_105', 'note_off_76', 'note_on_98', 'note_on_102', 'note_on_105', 'note_on_90', 'note_on_81', 'note_on_74', 'note_on_86', 'time_shift_29', 'note_off_86', 'note_on_86', 'time_shift_29', 'note_off_86', 'time_shift_59', 'note_on_83', 'time_shift_29', 'note_off_83', 'note_on_83', 'time_shift_29', 'note_off_83', 'time_shift_59', 'note_off_102', 'note_off_105', 'note_off_90', 'note_off_81', 'note_off_74', 'time_shift_2', 'note_off_98', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Done\n",
            "[51, 63, 66, 70, 271, 179, 191, 194, 198, 271, 51, 63, 66, 70, 271, 179, 191, 194, 198, 286, 51, 63, 66, 70, 271, 179, 191, 194, 198, 286, 51, 63, 66, 70, 271, 179, 191, 194, 198, 271, 51, 63, 66, 70, 271, 179, 191, 194, 198, 286, 51, 63, 66, 70, 271, 179, 191, 194, 198, 286, 54, 61, 66, 70, 271, 182, 189, 194, 198, 271, 54, 61, 66, 70, 271, 182, 189, 194, 198, 286, 54, 61, 66, 70, 271, 182, 189, 194, 198, 286, 54, 61, 66, 70, 271, 182, 189, 194, 198, 271, 54, 61, 66, 70, 271, 182, 189, 194, 198, 286, 54, 61, 66, 70, 271, 182, 189, 194, 198, 286, 49, 61, 65, 68, 271, 177, 189, 193, 196, 271, 49, 61, 65, 68, 271, 177, 189, 193, 196, 286, 49, 61, 65, 68, 271, 177, 189, 193, 196, 286, 49, 61, 65, 68, 271, 177, 189, 193, 196, 271, 49, 61, 65, 68, 271, 177, 189, 193, 196, 286, 49, 61, 65, 68, 271, 177, 189, 193, 196, 286, 44, 63, 68, 71, 271, 172, 191, 196, 199, 271, 44, 63, 68, 71, 271, 172, 191, 196, 199, 286, 44, 63, 68, 71, 271, 172, 191, 196, 199, 286, 44, 63, 68, 71, 271, 172, 191, 196, 199, 271]\n",
            "['note_on_50', 'note_on_62', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_50', 'note_off_62', 'note_off_65', 'note_off_69', 'time_shift_14', 'note_on_50', 'note_on_62', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_50', 'note_off_62', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_50', 'note_on_62', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_50', 'note_off_62', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_50', 'note_on_62', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_50', 'note_off_62', 'note_off_65', 'note_off_69', 'time_shift_14', 'note_on_50', 'note_on_62', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_50', 'note_off_62', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_50', 'note_on_62', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_50', 'note_off_62', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_53', 'note_on_60', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_53', 'note_off_60', 'note_off_65', 'note_off_69', 'time_shift_14', 'note_on_53', 'note_on_60', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_53', 'note_off_60', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_53', 'note_on_60', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_53', 'note_off_60', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_53', 'note_on_60', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_53', 'note_off_60', 'note_off_65', 'note_off_69', 'time_shift_14', 'note_on_53', 'note_on_60', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_53', 'note_off_60', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_53', 'note_on_60', 'note_on_65', 'note_on_69', 'time_shift_14', 'note_off_53', 'note_off_60', 'note_off_65', 'note_off_69', 'time_shift_29', 'note_on_48', 'note_on_60', 'note_on_64', 'note_on_67', 'time_shift_14', 'note_off_48', 'note_off_60', 'note_off_64', 'note_off_67', 'time_shift_14', 'note_on_48', 'note_on_60', 'note_on_64', 'note_on_67', 'time_shift_14', 'note_off_48', 'note_off_60', 'note_off_64', 'note_off_67', 'time_shift_29', 'note_on_48', 'note_on_60', 'note_on_64', 'note_on_67', 'time_shift_14', 'note_off_48', 'note_off_60', 'note_off_64', 'note_off_67', 'time_shift_29', 'note_on_48', 'note_on_60', 'note_on_64', 'note_on_67', 'time_shift_14', 'note_off_48', 'note_off_60', 'note_off_64', 'note_off_67', 'time_shift_14', 'note_on_48', 'note_on_60', 'note_on_64', 'note_on_67', 'time_shift_14', 'note_off_48', 'note_off_60', 'note_off_64', 'note_off_67', 'time_shift_29', 'note_on_48', 'note_on_60', 'note_on_64', 'note_on_67', 'time_shift_14', 'note_off_48', 'note_off_60', 'note_off_64', 'note_off_67', 'time_shift_29', 'note_on_43', 'note_on_62', 'note_on_67', 'note_on_70', 'time_shift_14', 'note_off_43', 'note_off_62', 'note_off_67', 'note_off_70', 'time_shift_14', 'note_on_43', 'note_on_62', 'note_on_67', 'note_on_70', 'time_shift_14', 'note_off_43', 'note_off_62', 'note_off_67', 'note_off_70', 'time_shift_29', 'note_on_43', 'note_on_62', 'note_on_67', 'note_on_70', 'time_shift_14', 'note_off_43', 'note_off_62', 'note_off_67', 'note_off_70', 'time_shift_29', 'note_on_43', 'note_on_62', 'note_on_67', 'note_on_70', 'time_shift_14', 'note_off_43', 'note_off_62', 'note_off_67', 'note_off_70', 'time_shift_14']\n",
            "Done\n",
            "[46, 58, 62, 65, 69, 381, 281, 186, 58, 190, 62, 301, 193, 65, 197, 69, 299, 193, 259, 45, 174, 55, 186, 60, 190, 64, 67, 197, 376, 38, 173, 50, 183, 188, 60, 192, 64, 195, 67, 376, 166, 43, 178, 58, 188, 62, 192, 65, 195, 69, 381, 281, 186, 58, 190, 62, 301, 193, 65, 197, 69, 299, 193, 259, 171, 45, 55, 186, 60, 190, 64, 67, 197, 376, 173, 46, 183, 188, 60, 192, 65, 195, 69, 72, 376, 174, 46, 58, 188, 62, 193, 65, 197, 69, 200, 381, 281, 186, 58, 190, 62, 301, 193, 65, 197, 69, 299, 193, 259, 45, 174, 55, 186, 60, 190, 64, 67, 197, 376, 38, 173, 50, 183, 55, 57, 188, 60, 192, 64, 195, 376, 166, 43, 178, 183, 185, 58, 188, 62, 192, 65, 69, 381, 281, 186, 58, 190, 62, 301, 193, 65, 197, 69, 299, 193, 259, 171, 45, 55, 186, 60, 190, 64, 67, 197, 376, 173, 46, 183, 58, 188, 60, 192, 65, 195, 69, 72, 316, 200, 74, 316, 174, 186, 188, 193, 197, 202, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "['note_on_45', 'note_on_57', 'note_on_61', 'note_on_64', 'note_on_68', 'time_shift_124', 'time_shift_24', 'note_off_57', 'note_on_57', 'note_off_61', 'note_on_61', 'time_shift_44', 'note_off_64', 'note_on_64', 'note_off_68', 'note_on_68', 'time_shift_42', 'note_off_64', 'time_shift_2', 'note_on_44', 'note_off_45', 'note_on_54', 'note_off_57', 'note_on_59', 'note_off_61', 'note_on_63', 'note_on_66', 'note_off_68', 'time_shift_119', 'note_on_37', 'note_off_44', 'note_on_49', 'note_off_54', 'note_off_59', 'note_on_59', 'note_off_63', 'note_on_63', 'note_off_66', 'note_on_66', 'time_shift_119', 'note_off_37', 'note_on_42', 'note_off_49', 'note_on_57', 'note_off_59', 'note_on_61', 'note_off_63', 'note_on_64', 'note_off_66', 'note_on_68', 'time_shift_124', 'time_shift_24', 'note_off_57', 'note_on_57', 'note_off_61', 'note_on_61', 'time_shift_44', 'note_off_64', 'note_on_64', 'note_off_68', 'note_on_68', 'time_shift_42', 'note_off_64', 'time_shift_2', 'note_off_42', 'note_on_44', 'note_on_54', 'note_off_57', 'note_on_59', 'note_off_61', 'note_on_63', 'note_on_66', 'note_off_68', 'time_shift_119', 'note_off_44', 'note_on_45', 'note_off_54', 'note_off_59', 'note_on_59', 'note_off_63', 'note_on_64', 'note_off_66', 'note_on_68', 'note_on_71', 'time_shift_119', 'note_off_45', 'note_on_45', 'note_on_57', 'note_off_59', 'note_on_61', 'note_off_64', 'note_on_64', 'note_off_68', 'note_on_68', 'note_off_71', 'time_shift_124', 'time_shift_24', 'note_off_57', 'note_on_57', 'note_off_61', 'note_on_61', 'time_shift_44', 'note_off_64', 'note_on_64', 'note_off_68', 'note_on_68', 'time_shift_42', 'note_off_64', 'time_shift_2', 'note_on_44', 'note_off_45', 'note_on_54', 'note_off_57', 'note_on_59', 'note_off_61', 'note_on_63', 'note_on_66', 'note_off_68', 'time_shift_119', 'note_on_37', 'note_off_44', 'note_on_49', 'note_off_54', 'note_on_54', 'note_on_56', 'note_off_59', 'note_on_59', 'note_off_63', 'note_on_63', 'note_off_66', 'time_shift_119', 'note_off_37', 'note_on_42', 'note_off_49', 'note_off_54', 'note_off_56', 'note_on_57', 'note_off_59', 'note_on_61', 'note_off_63', 'note_on_64', 'note_on_68', 'time_shift_124', 'time_shift_24', 'note_off_57', 'note_on_57', 'note_off_61', 'note_on_61', 'time_shift_44', 'note_off_64', 'note_on_64', 'note_off_68', 'note_on_68', 'time_shift_42', 'note_off_64', 'time_shift_2', 'note_off_42', 'note_on_44', 'note_on_54', 'note_off_57', 'note_on_59', 'note_off_61', 'note_on_63', 'note_on_66', 'note_off_68', 'time_shift_119', 'note_off_44', 'note_on_45', 'note_off_54', 'note_on_57', 'note_off_59', 'note_on_59', 'note_off_63', 'note_on_64', 'note_off_66', 'note_on_68', 'note_on_71', 'time_shift_59', 'note_off_71', 'note_on_73', 'time_shift_59', 'note_off_45', 'note_off_57', 'note_off_59', 'note_off_64', 'note_off_68', 'note_off_73', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Done\n",
            "[62, 55, 43, 70, 82, 346, 210, 81, 286, 72, 286, 200, 286, 190, 183, 171, 198, 209, 84, 65, 58, 46, 72, 316, 212, 94, 316, 222, 94, 89, 74, 262, 87, 265, 217, 262, 215, 265, 202, 86, 271, 214, 271, 193, 186, 174, 200, 222, 96, 69, 84, 260, 86, 260, 98, 263, 212, 260, 214, 267, 197, 86, 271, 214, 271, 224, 226, 94, 84, 70, 261, 82, 266, 212, 261, 210, 266, 198, 82, 271, 210, 271, 82, 70, 39, 51, 58, 257, 222, 345, 210, 81, 286, 198, 69, 286, 197, 286, 167, 179, 186, 209, 84, 69, 41, 53, 60, 316, 212, 93, 316, 197, 221, 93, 89, 70, 262, 87, 265, 217, 262, 215, 265, 198, 86, 271, 214, 271, 169, 181, 188, 221, 94, 72, 84, 260, 86, 257, 96, 266, 212, 260, 214, 267, 200, 86, 271, 214, 271, 222, 93, 84, 74, 257, 224, 260, 82, 266, 212, 261, 210, 266, 202, 82, 271, 210, 271, 221, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "['note_on_61', 'note_on_54', 'note_on_42', 'note_on_69', 'note_on_81', 'time_shift_89', 'note_off_81', 'note_on_80', 'time_shift_29', 'note_on_71', 'time_shift_29', 'note_off_71', 'time_shift_29', 'note_off_61', 'note_off_54', 'note_off_42', 'note_off_69', 'note_off_80', 'note_on_83', 'note_on_64', 'note_on_57', 'note_on_45', 'note_on_71', 'time_shift_59', 'note_off_83', 'note_on_93', 'time_shift_59', 'note_off_93', 'note_on_93', 'note_on_88', 'note_on_73', 'time_shift_5', 'note_on_86', 'time_shift_8', 'note_off_88', 'time_shift_5', 'note_off_86', 'time_shift_8', 'note_off_73', 'note_on_85', 'time_shift_14', 'note_off_85', 'time_shift_14', 'note_off_64', 'note_off_57', 'note_off_45', 'note_off_71', 'note_off_93', 'note_on_95', 'note_on_68', 'note_on_83', 'time_shift_3', 'note_on_85', 'time_shift_3', 'note_on_97', 'time_shift_6', 'note_off_83', 'time_shift_3', 'note_off_85', 'time_shift_10', 'note_off_68', 'note_on_85', 'time_shift_14', 'note_off_85', 'time_shift_14', 'note_off_95', 'note_off_97', 'note_on_93', 'note_on_83', 'note_on_69', 'time_shift_4', 'note_on_81', 'time_shift_9', 'note_off_83', 'time_shift_4', 'note_off_81', 'time_shift_9', 'note_off_69', 'note_on_81', 'time_shift_14', 'note_off_81', 'time_shift_14', 'note_on_81', 'note_on_69', 'note_on_38', 'note_on_50', 'note_on_57', 'time_shift_0', 'note_off_93', 'time_shift_88', 'note_off_81', 'note_on_80', 'time_shift_29', 'note_off_69', 'note_on_68', 'time_shift_29', 'note_off_68', 'time_shift_29', 'note_off_38', 'note_off_50', 'note_off_57', 'note_off_80', 'note_on_83', 'note_on_68', 'note_on_40', 'note_on_52', 'note_on_59', 'time_shift_59', 'note_off_83', 'note_on_92', 'time_shift_59', 'note_off_68', 'note_off_92', 'note_on_92', 'note_on_88', 'note_on_69', 'time_shift_5', 'note_on_86', 'time_shift_8', 'note_off_88', 'time_shift_5', 'note_off_86', 'time_shift_8', 'note_off_69', 'note_on_85', 'time_shift_14', 'note_off_85', 'time_shift_14', 'note_off_40', 'note_off_52', 'note_off_59', 'note_off_92', 'note_on_93', 'note_on_71', 'note_on_83', 'time_shift_3', 'note_on_85', 'time_shift_0', 'note_on_95', 'time_shift_9', 'note_off_83', 'time_shift_3', 'note_off_85', 'time_shift_10', 'note_off_71', 'note_on_85', 'time_shift_14', 'note_off_85', 'time_shift_14', 'note_off_93', 'note_on_92', 'note_on_83', 'note_on_73', 'time_shift_0', 'note_off_95', 'time_shift_3', 'note_on_81', 'time_shift_9', 'note_off_83', 'time_shift_4', 'note_off_81', 'time_shift_9', 'note_off_73', 'note_on_81', 'time_shift_14', 'note_off_81', 'time_shift_14', 'note_off_92', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Done\n",
            "[55, 381, 381, 306, 62, 381, 381, 306, 72, 381, 381, 381, 381, 356, 183, 51, 381, 381, 306, 190, 62, 381, 381, 306, 200, 69, 381, 381, 381, 381, 356, 55, 179, 381, 381, 306, 190, 62, 381, 381, 306, 70, 197, 381, 381, 381, 381, 356, 183, 48, 381, 381, 306, 190, 62, 381, 381, 306, 198, 69, 381, 381, 381, 381, 356, 55, 176, 381, 381, 306, 190, 62, 381, 381, 306, 72, 197, 381, 381, 381, 381, 356, 183, 51, 381, 381, 306, 190, 62, 381, 381, 306, 200, 69, 381, 381, 381, 381, 356, 55, 179, 381, 381, 306, 190, 62, 381, 381, 306, 70, 197, 381, 381, 381, 381, 356, 183, 48, 381, 381, 306, 190, 62, 381, 381, 306, 198, 69, 381, 381, 381, 381, 356, 55, 176, 381, 381, 306, 190, 62, 381, 381, 306, 72, 197, 381, 381, 381, 381, 356, 183, 51, 381, 381, 306, 190, 62, 381, 381, 306, 200, 69, 381, 381, 381, 381, 356, 55, 179, 381, 381, 306, 190, 62, 381, 381, 306, 70, 197, 381, 381, 381, 381, 356, 183, 48, 381, 381, 306, 190, 62, 381, 381, 306, 198, 69, 381, 381, 381, 381, 356, 55, 176, 381, 381, 306, 190, 62, 381, 381, 306, 72, 197, 381, 381, 381, 381, 356, 183, 51]\n",
            "['note_on_54', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_71', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_off_54', 'note_on_50', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_71', 'note_on_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_on_54', 'note_off_50', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_69', 'note_off_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_off_54', 'note_on_47', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_69', 'note_on_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_on_54', 'note_off_47', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_71', 'note_off_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_off_54', 'note_on_50', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_71', 'note_on_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_on_54', 'note_off_50', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_69', 'note_off_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_off_54', 'note_on_47', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_69', 'note_on_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_on_54', 'note_off_47', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_71', 'note_off_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_off_54', 'note_on_50', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_71', 'note_on_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_on_54', 'note_off_50', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_69', 'note_off_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_off_54', 'note_on_47', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_69', 'note_on_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_on_54', 'note_off_47', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_off_61', 'note_on_61', 'time_shift_124', 'time_shift_124', 'time_shift_49', 'note_on_71', 'note_off_68', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_124', 'time_shift_99', 'note_off_54', 'note_on_50']\n",
            "Done\n",
            "MIDI files generated and saved!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}